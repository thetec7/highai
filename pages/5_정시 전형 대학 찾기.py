from openai import OpenAI
import streamlit as st
import pandas as pd
import numpy as np
import re

API_KEY = st.secrets["openai_api_key"]

with st.sidebar:
    st.subheader("HighAI")

st.set_page_config(
    page_title="HighAI",
    page_icon="ğŸ“",
    layout="centered"
)

st.title("ğŸ’¬ ì •ì‹œ ì „í˜• ëŒ€í•™ ì°¾ê¸°")
st.caption("**âœ… ì‚¬ìš©ë°©ë²• :** í¬ë§ ì „ê³µê³¼ ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ì„ ì…ë ¥í•˜ê³  'ì§€ì› ëŒ€í•™ ê²€ìƒ‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.  \n**âš ï¸ ì£¼ì˜ì‚¬í•­ :** ê²€ìƒ‰ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ë°˜ë“œì‹œ ë‹´ì„ ì„ ìƒë‹˜ê³¼ ìƒë‹´í•˜ì—¬ ì‹ ì¤‘í•˜ê²Œ ê²°ì •í•˜ì„¸ìš”.")

def askGpt(prompt, api_key):
    client = OpenAI(api_key=api_key)
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", 
            messages=[{"role": "user", "content": prompt}]
        )
        gptResponse = response.choices[0].message.content
        return gptResponse
    except Exception as e:
        print(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.error("AI ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return ""

def main():
    try:
        df = pd.read_csv("data/Regular_Results1.csv")
        df['í•©ê²© ë°±ë¶„ìœ„'] = pd.to_numeric(df['í•©ê²© ë°±ë¶„ìœ„'], errors='coerce')
        df['ë…„ë„'] = pd.to_numeric(df['ë…„ë„'], errors='coerce')
        df.dropna(subset=['í•©ê²© ë°±ë¶„ìœ„', 'ë…„ë„'], inplace=True)
    except FileNotFoundError:
        st.error("`Regular_Results1.csv` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ `data` í´ë” ì•ˆì— ì˜¬ë°”ë¥´ê²Œ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    except KeyError as e:
        st.error(f"CSV íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {e}. 'ëŒ€í•™ëª…', 'í•™ê³¼ëª…', 'ì „í˜•ëª…', 'ë…„ë„', 'í•©ê²© ë°±ë¶„ìœ„' ì»¬ëŸ¼ì´ ì •í™•íˆ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    col1, col2 = st.columns(2)
    with col1:
        desired_major = st.text_input("í¬ë§ ì „ê³µ", placeholder="ì˜ˆ: ì»´í“¨í„°ê³µí•™ / ê¸°ê³„ê³µí•™ / ì—­ì‚¬")
    with col2:
        percentile_input = st.text_input("ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ", placeholder="ì˜ˆ: 85.5 (ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€)")

    if st.button("ì§€ì› ëŒ€í•™ ê²€ìƒ‰"):
        if not desired_major or not percentile_input:
            st.warning("í¬ë§ ì „ê³µê³¼ ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ì„ ëª¨ë‘ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            return

        try:
            user_percentile = float(percentile_input)
            if not (0.0 <= user_percentile <= 100.0):
                st.error("ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ì€ 0.0ë¶€í„° 100.0 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
        except ValueError:
            st.error("ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ì„ ì˜¬ë°”ë¥¸ ìˆ«ì í˜•ì‹(ì˜ˆ: 85.5)ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        result_container = st.container(border=True)

        with st.spinner("ì§€ì› ê°€ëŠ¥ ëŒ€í•™ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
            major_prompt = f"'{desired_major}' ì „ê³µê³¼ ê°€ì¥ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ë˜ê±°ë‚˜ ë™ì¼ ê³„ì—´ì˜ í•™ê³¼ëª…ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ 5ê°œ ì •ë„ ë‚˜ì—´í•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¡ ì´ë‚˜ ì„¤ëª… ì—†ì´ í•™ê³¼ëª…ë§Œ ë‚˜ì—´í•´ì£¼ì„¸ìš”. ì˜ˆì‹œ: ì»´í“¨í„°ê³µí•™, ì†Œí”„íŠ¸ì›¨ì–´ê³µí•™, ì¸ê³µì§€ëŠ¥í•™ê³¼, ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼"
            related_majors_str = askGpt(major_prompt, API_KEY)

            related_majors = []
            if related_majors_str:
                related_majors = [m.strip() for m in related_majors_str.split(',') if m.strip()]

            if desired_major not in related_majors:
                related_majors.insert(0, desired_major)

            seen = set()
            unique_related_majors = []
            for major in related_majors:
                if major not in seen:
                    unique_related_majors.append(major)
                    seen.add(major)
            
            major_pattern = '|'.join(re.escape(m) for m in unique_related_majors)

            df_target_year = df[df['ë…„ë„'] == 2024].copy()
            
            filtered_by_major_df = df_target_year[df_target_year['í•™ê³¼ëª…'].str.contains(major_pattern, case=False, na=False)].copy()

            if filtered_by_major_df.empty:
                st.warning(f"'{desired_major}'(ì™€)ê³¼ ìœ ì‚¬í•œ ì „ê³µìœ¼ë¡œ 2024í•™ë…„ë„ ë°ì´í„°ê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            filtered_by_major_df['match_priority'] = filtered_by_major_df['í•™ê³¼ëª…'].apply(lambda x: 0 if desired_major.lower() in x.lower() else 1)
            
            filtered_by_major_df['ë°±ë¶„ìœ„_ì°¨ì´'] = abs(filtered_by_major_df['í•©ê²© ë°±ë¶„ìœ„'] - user_percentile)
            
            percentile_filtered_df = filtered_by_major_df[filtered_by_major_df['ë°±ë¶„ìœ„_ì°¨ì´'] <= 5.0].copy()

            if percentile_filtered_df.empty:
                st.info(f"ì…ë ¥í•˜ì‹  ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê·  '{user_percentile}'ê³¼ 5.0 ë°±ë¶„ìœ„ ì´ë‚´ì˜ ì°¨ì´ë¥¼ ë³´ì´ëŠ” '{desired_major}' ê³„ì—´ì˜ 2024í•™ë…„ë„ ëŒ€í•™ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°±ë¶„ìœ„ë‚˜ ì „ê³µì„ ì…ë ¥í•´ë³´ì„¸ìš”.")
                return

            recommended_universities_unique = percentile_filtered_df \
                .sort_values(by=['match_priority', 'ë°±ë¶„ìœ„_ì°¨ì´', 'í•©ê²© ë°±ë¶„ìœ„'], ascending=[True, True, False]) \
                .drop_duplicates(subset=['ëŒ€í•™ëª…', 'í•™ê³¼ëª…']) \
                .head(12) # ìµœëŒ€ 12ê°œ ëŒ€í•™ë§Œ í‘œì‹œ

            with result_container:
                if recommended_universities_unique.empty:
                    st.info("í˜„ì¬ ì…ë ¥ëœ ì •ë³´ë¡œëŠ” ì¶”ì²œí•  ë§Œí•œ ëŒ€í•™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬ë§ ì „ê³µê³¼ ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê· ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                else:
                    for index, row in recommended_universities_unique.iterrows(): # ë³€ìˆ˜ëª… row_2025 -> row ë¡œ ë³€ê²½ (ë” ì¼ë°˜ì )
                        university_name = row['ëŒ€í•™ëª…'].strip()
                        major_name = row['í•™ê³¼ëª…'].strip()
                        
                        historical_data_for_pair = df[
                            (df['ëŒ€í•™ëª…'] == university_name) & 
                            (df['í•™ê³¼ëª…'] == major_name) &
                            (df['ë…„ë„'].between(2023, 2024))
                        ].sort_values(by='ë…„ë„', ascending=False)

                        st.markdown(f"#### ğŸ“ **{university_name} - {major_name}**")

                        if not historical_data_for_pair.empty:
                            details_str = ""
                            for year, year_group in historical_data_for_pair.groupby('ë…„ë„'):
                                details_str += f"###### ğŸ—“ï¸ **{int(year)}í•™ë…„ë„ ì…ì‹œ ê²°ê³¼**\n"
                                for _, hist_row in year_group.iterrows():
                                    details_str += f"- **ì „í˜•ëª…:** {hist_row['ì „í˜•ëª…']},     **70% ë°±ë¶„ìœ„:** {hist_row['í•©ê²© ë°±ë¶„ìœ„']:.2f} %\n"
                            st.markdown(details_str) 
                        else:
                            st.markdown(f"    - í•´ë‹¹ í•™ê³¼ì— ëŒ€í•œ 2023-2024í•™ë…„ë„ ì…ì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.markdown("""
                    <p style='color:#696969 ; font-size:14px;'>
                    ì •ì‹œ ì „í˜•ì—ì„œë„ ìˆ˜ëŠ¥ ì ìˆ˜ ì™¸ì— ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆìœ¼ë©°, ëŒ€í•™ ë° ëª¨ì§‘ë‹¨ìœ„ë³„ë¡œ ë°˜ì˜ ë¹„ìœ¨ì´ ìƒì´í•©ë‹ˆë‹¤. ìµœì ì˜ ì§€ì› ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•´ ë‹´ì„ ì„ ìƒë‹˜ê³¼ì˜ ì‹¬ì¸µ ìƒë‹´ì„ í†µí•´ ìµœì¢… ê²°ì •ì„ ì‹ ì¤‘í•˜ê²Œ ë‚´ë¦¬ì‹œê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
                    </p>
                    """, unsafe_allow_html=True)

if __name__ == '__main__':
    main()